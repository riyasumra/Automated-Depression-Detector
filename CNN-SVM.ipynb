{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Major1\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Major1\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load GoogleNet model pretrained on ImageNet, set it to evaluation mode, and use the CPU\n",
    "gn = models.googlenet(pretrained=True)\n",
    "gn.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Define the transformation to convert images to tensor\n",
    "img_transform = transforms.ToTensor()\n",
    "\n",
    "# Create a DataFrame to store the output features and target labels\n",
    "df = pd.DataFrame(columns=list(range(1000)))  # assuming 1000 output features\n",
    "target = pd.DataFrame(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RIYA SUMRA\\AppData\\Local\\Temp\\ipykernel_7788\\4164665976.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, feature_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir('final_image_data'):\n",
    "    for j in os.listdir('final_image_data/' + i):\n",
    "        for k in os.listdir('final_image_data/' + i + '/' + j):\n",
    "            # Load and transform the image\n",
    "            im = Image.open('final_image_data/' + i + '/' + j + '/' + k)\n",
    "            transformed_img = img_transform(im).unsqueeze(0)  # Add batch dimension\n",
    "            \n",
    "            # Forward pass on the model using CPU\n",
    "            features = gn.forward(torch.autograd.Variable(transformed_img)).detach().numpy()\n",
    "            \n",
    "            # Convert the feature and target row into DataFrames\n",
    "            feature_df = pd.DataFrame(features, columns=list(range(1000)))\n",
    "            target_df = pd.DataFrame([int(j)], columns=['target'])\n",
    "            \n",
    "            # Concatenate feature_df and target_df to df and target, respectively\n",
    "            df = pd.concat([df, feature_df], ignore_index=True)\n",
    "            target = pd.concat([target, target_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test=train_test_split(df,target[0],train_size=0.8)\n",
    "#test-train split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target['target'], train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='linear',probability=True)\n",
    "#SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on test set: 0.945\n",
      "Model Accuracy on train set: 0.9689583333333334\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_train and y_test are integer arrays\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Fit the model and evaluate\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Model Accuracy on test set:\", model.score(x_test, y_test))\n",
    "print(\"Model Accuracy on train set:\", model.score(x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_svm.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn import svm\n",
    "import joblib\n",
    "joblib.dump(model, 'my_svm.pkl')  # Save the model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
